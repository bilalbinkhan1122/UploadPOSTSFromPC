import os
import requests
from concurrent.futures import ThreadPoolExecutor
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
import uuid
import urllib.parse
from colorama import init
import sys
import time
import threading
import json
init()
RED = '\033[1;91m'
WHITE = '\033[1;97m'
GREEN = '\033[1;32m' 
YELLOW = '\033[1;33m'
BLUE = '\033[1;34m'
ORANGE = '\033[1;35m'
CYAN    = '\033[1;36;40m'
RESET   = '\033[0m'
DARKGREEN = '\033[32;5m'
BLINK = '\033[5;37;40m'





def handle_post_response(response_text):
    try:
        # Parse the JSON response
        response = json.loads(response_text)
        
        # Extract the relevant data from the response
        data = response.get("data", {}).get("xfamily_content_create", {})
        items = data.get("items", [])
        errors = data.get("errors", {})
        
        # Check for errors first - if any error exists, return None
        if any(value is not None for value in errors.values()):
            return None
        
        # If items are not empty, post was successful
        if items:
            # Try to get post_id if available
            post_id = items[0].get("story", {}).get("post_id")
            if post_id:
                return post_id
            
            # If post_id is not found, try to get pending_publish_content_id
            pending_publish_content_id = items[0].get("pending_publish_content_id")
            if pending_publish_content_id:
                return pending_publish_content_id
            
            # If pending_publish_content_id is null, return 'Group'
            if pending_publish_content_id is None:
                return "Group"
            
            # If neither post_id nor pending_publish_content_id is found, return None
            return None
        
        # If no items found, return None
        return None
    
    except json.JSONDecodeError:
        # Return None in case of a JSON parse error
        print("Failed to parse response. Invalid JSON.")
        return None
    
    except Exception as e:
        # Handle any unexpected errors (e.g., KeyError, IndexError)
        print(f"An error occurred: {e}")
        return None





    
def add_before_after_message(message):
    before_text = ""
    after_text = ""

    # Read before_message.txt if it exists
    try:
        with open('before_message.txt', 'r') as before_file:
            before_text = before_file.read()
    except FileNotFoundError:
        pass  # Ignore if file does not exist

    # Read after_message.txt if it exists
    try:
        with open('after_message.txt', 'r') as after_file:
            after_text = after_file.read()
    except FileNotFoundError:
        pass  # Ignore if file does not exist

    # Read main_message.txt if it exists and replace the default message
    try:
        with open('main_message.txt', 'r') as main_message_file:
            main_message = main_message_file.read()
            # Replace default message even if main_message contains only spaces or newlines
            if main_message != "":
                message = main_message
    except FileNotFoundError:
        pass  # Ignore if file does not exist

    # Construct the final message
    final_message = f"{before_text}{message}{after_text}"
    return final_message



def login():
 global fb_dtsg
 global coki
 global page_access_token
 global pgid
 global adaccount
 global token
 global uid
 coki = input('COKI : ')



 while True:
  
   if "i_user" in coki:
     parts = coki.split(';')
     filtered_parts = [part for part in parts if 'i_user' not in part]
     cok2 = ';'.join(filtered_parts)
   else:
     cok2 = coki

 
   coki = (coki.rstrip("\n"))  
   uid = re.search('c_user=(.*?);', coki)[1]
 


 
   headers = {
    'Host': 'business.facebook.com',
    'Sec-Ch-Ua': '"Not=A?Brand";v="99", "Chromium";v="118"',
    'Sec-Ch-Ua-Mobile': '?0',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Accept': '*/*',
    'Sec-Fetch-Site': 'none',
    'Sec-Fetch-Mode': 'cors',
    'Sec-Fetch-Dest': 'empty',
    # 'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'en-US,en;q=0.9',
    'Cookie': cok2,
}

   params = {
    'twofac_next': 'https://business.facebook.com/content_management',
    'type': 'avoid_bypass',
    'app_id': '0',
    'save_device': '0',
}

   response = requests.get(
    'https://business.facebook.com/security/twofactor/reauth/',
    params=params,
    headers=headers, allow_redirects=False,proxies=proxies
)
   if 'DTSGInitialData' not in response.text:
    print(f"{RED}Login Failed : {coki} {RESET}")
    coki = input('Input Cookie : ')
    continue
 
   fb_dtsg = re.search(r'\["DTSGInitialData",\[],{"token":"(.*?)"', response.text)[1]
  
   break
  



 headers = {
    'Host': 'adsmanager.facebook.com',
    'Sec-Ch-Ua': '"Not=A?Brand";v="99", "Chromium";v="118"',
    'Sec-Ch-Ua-Mobile': '?0',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Accept': '*/*',
    'Sec-Fetch-Site': 'none',
    'Sec-Fetch-Mode': 'cors',
    'Sec-Fetch-Dest': 'empty',
    'Accept-Language': 'en-US,en;q=0.9',
    'Cookie': cok2,
}

 response = requests.get(
    'https://adsmanager.facebook.com/adsmanager/manage/campaigns',
    headers=headers,
    proxies=proxies,
    allow_redirects=False
)

 





 

 adaccount = re.search(r'campaigns\?act=(.*?)&', response.headers['Location'])[1]






 headers = {
    'Host': 'adsmanager.facebook.com',
    'Sec-Ch-Ua': '"Not=A?Brand";v="99", "Chromium";v="118"',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Sec-Ch-Ua-Mobile': '?0',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
    'Origin': 'https://adsmanager.facebook.com',
    'Sec-Fetch-Site': 'same-origin',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Dest': 'document',
    'Referer': 'https://adsmanager.facebook.com',
    'Accept-Language': 'en-US,en;q=0.9',
    'Cookie': coki,
}

 params = {
    'act': adaccount,
    'breakdown_regrouping': '1',
}

 response = requests.get('https://adsmanager.facebook.com/adsmanager/manage/campaigns', params=params, headers=headers, proxies=proxies)

 token = re.search('window.__accessToken="(.*?)"', response.text)[1]




 headers = {
    'Host': 'graph.facebook.com',
    'Sec-Ch-Ua': '"Not=A?Brand";v="99", "Chromium";v="118"',
    'Accept': 'application/json, text/plain, */*',
    'Sec-Ch-Ua-Mobile': '?0',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Sec-Fetch-Site': 'same-origin',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Dest': 'document',
    'Accept-Language': 'en-US,en;q=0.9',
    'Cookie': coki,
}

 response = requests.get('https://graph.facebook.com/v21.0/me/accounts?access_token='+token+'&fields=access_token,id,name,picture,is_published&limit=999&fewfeedcors=0',  headers=headers, proxies=proxies)
# Example API endpoint

# Check if the request was successful
 if response.status_code == 200:
    # Parse JSON response
    response_data = response.json()  # Converts JSON text to Python dictionary
    
    # Extract 'data' field
    data = response_data.get("data", [])
    
    # Display names and IDs with numbering
    for index, item in enumerate(data, start=1):
        print(f"{index}. {item['name']} : {item['id']}")
    
    # Prompt user to select a number
    selection = int(input("Enter Number : ")) - 1
    
    # Validate selection
    if 0 <= selection < len(data):
        selected_item = data[selection]
        print(f"Selected Name: {selected_item['name']}")

        page_access_token = selected_item['access_token']
        pgid = selected_item['id']

        return(pgid)
                
        
    else:
        print("Invalid selection.")
 else:
    print(f"Request failed with status code: {response.status_code}")





def schedule_post(message, idnlink, type, timestamp):
        
        message = os.path.splitext(os.path.basename(message))[0]

        human_readable_date = datetime.fromtimestamp(int(timestamp)).strftime("%Y-%m-%d %H:%M:%S")


        if message == 'nan':
            message = ""
        message = add_before_after_message(message)
        message = str(message).replace('\n','\\n').replace('"','').replace('&','%26')
        

        

        client_mutation_id = str(uuid.uuid4())



        headers = {
    'Host': 'business.facebook.com',
    # 'Content-Length': '4933',
    'Sec-Ch-Ua': '"Not=A?Brand";v="99", "Chromium";v="118"',
    'Sec-Ch-Ua-Mobile': '?0',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'X-Fb-Friendly-Name': 'BusinessComposerStoryCreationMutation',
    'Sec-Ch-Ua-Platform-Version': '"19.0.0"',
    'Content-Type': 'application/x-www-form-urlencoded',
    'X-Asbd-Id': '129477',
    'Sec-Ch-Ua-Full-Version-List': '"Not=A?Brand";v="99.0.0.0", "Chromium";v="118.0.5993.159"',
    'Sec-Ch-Ua-Model': '""',
    'Sec-Ch-Prefers-Color-Scheme': 'dark',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Accept': '*/*',
    'Origin': 'https://business.facebook.com',
    'Sec-Fetch-Site': 'same-origin',
    'Sec-Fetch-Mode': 'cors',
    'Sec-Fetch-Dest': 'empty',
    'Referer': 'https://business.facebook.com/latest/composer/?ref=biz_web_home_create_post&asset_id='+pgid+'&nav_ref=internal_nav&context_ref=HOME',
    'Accept-Language': 'en-US,en;q=0.9',
    'Cookie': coki,
}
        

        data_string = build_data_string(group_ids, post_in_group, post_in_page, message, timestamp, idnlink, client_mutation_id)
        response = requests.post('https://business.facebook.com/api/graphql/',  headers=headers, data=data_string, proxies=proxies)

        checkpost = handle_post_response(response.text)
        if checkpost:
            return human_readable_date, checkpost, type
        elif checkpost is None:
            return None
        else:
            return (human_readable_date, response.text, type)

def collect_user_input():
    # Group input
    post_in_group = input("Do you want to post in a Group? (yes/no): ").strip().lower()
    group_ids = []
    if post_in_group == "yes":
        num_groups = int(input("How many groups do you want to post in?: "))
        for i in range(num_groups):
            group_id = input(f"Enter Group ID {i + 1}: ").strip()
            group_ids.append(group_id)

    # Ask if posting on Page is needed when posting in Groups
    post_in_page = "yes"  # Default to posting on Page
    if post_in_group == "yes":
        post_in_page = input("Do you also want to post on the Page? (yes/no): ").strip().lower()

    # Return all collected inputs
    return group_ids, post_in_group, post_in_page


def build_data_string(group_ids, post_in_group, post_in_page, message, timestamp, idnlink, client_mutation_id):

    if post_in_group == 'yes' and post_in_page == 'no':
        data = 'av='+pgid+'&__aaid=0&__user='+uid+'&__a=1&__req=2g&__hs=20093.HYP%3Abizweb_comet_pkg.2.1.0.0.0&dpr=1&__ccg=GOOD&__rev=1019152068&__comet_req=11&fb_dtsg='+fb_dtsg+'&qpl_active_flow_ids=744699792&fb_api_caller_class=RelayModern&fb_api_req_friendly_name=BusinessComposerStoryCreationMutation&variables=%7B%22input%22%3A%7B%22client_mutation_id%22%3A%22'+client_mutation_id+'%22%2C%22base%22%3A%7B%22actor_id%22%3A%22'+pgid+'%22%2C%22composer_entry_point%22%3A%22biz_web_home_create_post%22%2C%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%2C%22source%22%3A%22WWW%22%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22explicit_place_id%22%3A%22%22%2C%22audiences%22%3A%5B%7B%22business_presence%22%3A%7B%22business_presence_id%22%3A%22'+pgid+'%22%7D%7D%5D%2C%22request_review_data%22%3A%7B%22review_request_status%22%3Anull%7D%2C%22post_collaborators%22%3A%7B%22post_collaborators%22%3A%5B%5D%7D%2C%22comment_attached_posting%22%3Anull%2C%22post_publish_story_data%22%3A%7B%22resharing_frequency%22%3A%22ALWAYS%22%2C%22reshare_post_as_sticker%22%3A%22DISABLED%22%7D%2C%22boost_status%22%3A%7B%22is_boost_toggle_on%22%3Anull%2C%22is_boost_afterparty_eligible%22%3Anull%7D%7D%2C%22channels%22%3A%5B%22FACEBOOK_GROUP%22%5D%2C%22FACEBOOK_NEWS_FEED%22%3A%7B%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%7D%2C%22FACEBOOK_GROUP%22%3A%7B%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%2C%22group_ids%22%3A%5B%22' + ','.join([f'{gid}' for gid in group_ids]) + '%22%5D%7D%2C%22INSTAGRAM_POST%22%3A%7B%22unpublished_content_data%22%3Anull%7D%2C%22identities%22%3A%5B%22'+pgid+'%22%5D%2C%22ad_campaign_group%22%3Anull%2C%22raw_boosted_component_spec%22%3A%22null%22%2C%22logging%22%3A%7B%22composer_session_id%22%3A%22'+client_mutation_id+'%22%7D%7D%2C%22checkPhotosToReelsUpsellEligibility%22%3Atrue%7D&server_timestamps=true&doc_id=7824581757552022&fb_api_analytics_tags=%5B%22qpl_active_flow_ids%3D744699792%22%5D'
        return data
    elif post_in_group == 'no':
        data = 'av='+pgid+'&__aaid=0&__user='+uid+'&__a=1&__req=1c&__hs=20093.HYP%3Abizweb_comet_pkg.2.1.0.0.0&dpr=1&__ccg=GOOD&__rev=1019152068&__comet_req=11&fb_dtsg='+fb_dtsg+'&qpl_active_flow_ids=744699792&fb_api_caller_class=RelayModern&fb_api_req_friendly_name=BusinessComposerStoryCreationMutation&variables=%7B%22input%22%3A%7B%22client_mutation_id%22%3A%22'+client_mutation_id+'%22%2C%22base%22%3A%7B%22actor_id%22%3A%22'+pgid+'%22%2C%22composer_entry_point%22%3A%22biz_web_home_create_post%22%2C%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%2C%22source%22%3A%22WWW%22%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22explicit_place_id%22%3A%22%22%2C%22audiences%22%3A%5B%7B%22business_presence%22%3A%7B%22business_presence_id%22%3A%22'+pgid+'%22%7D%7D%5D%2C%22request_review_data%22%3A%7B%22review_request_status%22%3Anull%7D%2C%22post_collaborators%22%3A%7B%22post_collaborators%22%3A%5B%5D%7D%2C%22comment_attached_posting%22%3Anull%2C%22post_publish_story_data%22%3A%7B%22resharing_frequency%22%3A%22ALWAYS%22%2C%22reshare_post_as_sticker%22%3A%22DISABLED%22%7D%2C%22boost_status%22%3A%7B%22is_boost_toggle_on%22%3Anull%2C%22is_boost_afterparty_eligible%22%3Anull%7D%7D%2C%22channels%22%3A%5B%22FACEBOOK_NEWS_FEED%22%5D%2C%22FACEBOOK_NEWS_FEED%22%3A%7B%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%7D%2C%22FACEBOOK_GROUP%22%3Anull%2C%22INSTAGRAM_POST%22%3A%7B%22unpublished_content_data%22%3Anull%7D%2C%22identities%22%3A%5B%22'+pgid+'%22%5D%2C%22ad_campaign_group%22%3Anull%2C%22raw_boosted_component_spec%22%3A%22null%22%2C%22logging%22%3A%7B%22composer_session_id%22%3A%22'+client_mutation_id+'%22%7D%7D%2C%22checkPhotosToReelsUpsellEligibility%22%3Atrue%7D&server_timestamps=true&doc_id=7824581757552022&fb_api_analytics_tags=%5B%22qpl_active_flow_ids%3D744699792%22%5D'
        return data
    elif post_in_group == 'yes' and post_in_page == 'yes':
        data = 'av='+pgid+'&__aaid=0&__user='+uid+'&__a=1&__req=1s&__hs=20093.HYP%3Abizweb_comet_pkg.2.1.0.0.0&dpr=1&__ccg=GOOD&__rev=1019152241&__comet_req=11&fb_dtsg='+fb_dtsg+'&qpl_active_flow_ids=744699792&fb_api_caller_class=RelayModern&fb_api_req_friendly_name=BusinessComposerStoryCreationMutation&variables=%7B%22input%22%3A%7B%22client_mutation_id%22%3A%22'+client_mutation_id+'%22%2C%22base%22%3A%7B%22actor_id%22%3A%22'+pgid+'%22%2C%22composer_entry_point%22%3A%22biz_web_home_create_post%22%2C%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%2C%22source%22%3A%22WWW%22%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22explicit_place_id%22%3A%22%22%2C%22audiences%22%3A%5B%7B%22business_presence%22%3A%7B%22business_presence_id%22%3A%22'+pgid+'%22%7D%7D%5D%2C%22request_review_data%22%3A%7B%22review_request_status%22%3Anull%7D%2C%22post_collaborators%22%3A%7B%22post_collaborators%22%3A%5B%5D%7D%2C%22comment_attached_posting%22%3Anull%2C%22post_publish_story_data%22%3A%7B%22resharing_frequency%22%3A%22ALWAYS%22%2C%22reshare_post_as_sticker%22%3A%22DISABLED%22%7D%2C%22boost_status%22%3A%7B%22is_boost_toggle_on%22%3Anull%2C%22is_boost_afterparty_eligible%22%3Anull%7D%7D%2C%22channels%22%3A%5B%22FACEBOOK_NEWS_FEED%22%2C%22FACEBOOK_GROUP%22%5D%2C%22FACEBOOK_NEWS_FEED%22%3A%7B%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%7D%2C%22FACEBOOK_GROUP%22%3A%7B%22message%22%3A%7B%22ranges%22%3A%5B%5D%2C%22text%22%3A%22'+message+'%22%7D%2C%22unpublished_content_data%22%3A%7B%22scheduled_publish_time%22%3A'+str(timestamp)+'%2C%22unpublished_content_type%22%3A%22SCHEDULED%22%7D%2C%22attachments%22%3A%5B'+idnlink+'%5D%2C%22group_ids%22%3A%5B%22' + ','.join([f'{gid}' for gid in group_ids]) + '%22%5D%7D%2C%22INSTAGRAM_POST%22%3A%7B%22unpublished_content_data%22%3Anull%7D%2C%22identities%22%3A%5B%22'+pgid+'%22%5D%2C%22ad_campaign_group%22%3Anull%2C%22raw_boosted_component_spec%22%3A%22null%22%2C%22logging%22%3A%7B%22composer_session_id%22%3A%22'+client_mutation_id+'%22%7D%7D%2C%22checkPhotosToReelsUpsellEligibility%22%3Atrue%7D&server_timestamps=true&doc_id=7824581757552022&fb_api_analytics_tags=%5B%22qpl_active_flow_ids%3D744699792%22%5D'
        return data



def encode_url(url: str) -> str:
    """
    Encode a URL into its percent-encoded form.

    Args:
        url (str): The URL to encode.

    Returns:
        str: The percent-encoded URL.
    """
    return str(urllib.parse.quote(url, safe=''))

def get_album_title(album_folder):
    """Retrieve album title from Title.txt inside the album folder."""
    title_file_path = os.path.join(album_folder, "Title.txt")
    if os.path.exists(title_file_path):
        with open(title_file_path, "r", encoding="utf-8") as file:
            return file.read().strip()
    return ""

def upload_file(image_path):
  

    url = "https://upload-business.facebook.com/ajax/react_composer/attachments/photo/upload"
    headers = {
    "Sec-Ch-Ua": "\"Not=A?Brand\";v=\"99\", \"Chromium\";v=\"118\"",
    "Sec-Ch-Ua-Platform": "\"Windows\"",
    "Sec-Ch-Ua-Mobile": "?0",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
    "Accept": "*/*",
    "Origin": "https://business.facebook.com",
    "Sec-Fetch-Site": "same-site",
    "Sec-Fetch-Mode": "cors",
    "Sec-Fetch-Dest": "empty",
    "Referer": "https://business.facebook.com/",
    "Accept-Encoding": "deflate",
    "Accept-Language": "en-US,en;q=0.9",
    "Cookie": coki
}

    params = {
    'av': pgid,
    '__user': uid,
    '__a': '1',
    '__req': '1c',
    '__hs': '20092.HYP:bizweb_comet_pkg.2.1.0.0.0',
    'dpr': '1',
    '__ccg': 'GOOD',
    'fb_dtsg': fb_dtsg,
    'qpl_active_flow_ids': '744699792',
}

    files = {
        "source": (None, "8"),
        "profile_id": (None, uid),
        "waterfallxapp": (None, "comet"),
        "farr": (os.path.basename(image_path), open(image_path, "rb")),
        "upload_id": (None, "1024")
    }

    response = requests.post(url, headers=headers, files=files, params=params, proxies=proxies)
    if 'imageSrc' in response.text and 'photoID' in response.text:
        imgsrc = re.search('"imageSrc":"(.*?)"', response.text)[1].replace('\\/', '/')
        imgid = re.search('"photoID":"(.*?)"', response.text)[1]
        encodeurl = encode_url(imgsrc)
        idnlink = f'%7B%22photo%22%3A%7B%22photo_link_metadata%22%3A%7B%22link%22%3A%7B%22external%22%3A%7B%22url%22%3A%22{encodeurl}%22%7D%7D%7D%2C%22id%22%3A%22{imgid}%22%7D%7D'
        return idnlink
    else:
        return None
    

def upload_photos(image_file, unix_timestamp):
    idnlink = upload_file(image_file)
    human_readable_date, scheduledpost, type = schedule_post(image_file, idnlink, 'Photo', str(unix_timestamp))
    return human_readable_date, scheduledpost, type
    



def upload_albums(album_folder, album_title, unix_timestamp):
    
    # List all image files in the album folder
    image_files = [os.path.join(album_folder, f) for f in os.listdir(album_folder)
                   if f.lower().endswith(('jpg', 'jpeg', 'png', 'gif'))]
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {}
        idnlink = []
        # Schedule upload tasks
        for idx, image_file in enumerate(image_files):
            future = executor.submit(upload_file, image_file)
            futures[future] = (idx, image_file)


        for future in as_completed(futures):
            idx, image_file = futures[future]
            try:
                upload_link = future.result()
                idnlink.append(upload_link)
            except Exception as e:
                print(f"Error uploading image {idx} ({image_file}): {e}")
        idnlink = "%2C".join(idnlink)    
        human_readable_date, scheduledpost, type = schedule_post(album_title, idnlink, 'Album', str(unix_timestamp))
        return human_readable_date, scheduledpost, type, album_folder

def main(folder_path, start_time_str, delay_minutes, max_workers):
    
    # Parse the start time string to a datetime object
    start_time = datetime.strptime(start_time_str, "%I:%M%p %d/%m/%Y")
    current_time = start_time  
    # 1. Process images directly in the main folder
    main_folder_images = [os.path.join(folder_path, f) for f in os.listdir(folder_path)
                          if f.lower().endswith(('jpg', 'jpeg', 'png', 'gif'))]
    
    if main_folder_images:
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            

            # Schedule upload tasks
            for idx, image_file in enumerate(main_folder_images):
                unix_timestamp = int(current_time.timestamp())  
                future = executor.submit(upload_photos, image_file, str(unix_timestamp))                
                futures[future] = (idx, image_file)
                current_time += timedelta(minutes=delay_minutes)

            # Handle results as they complete
            for future in as_completed(futures):
                idx, image_file = futures[future]
                try:
                    human_readable_date, scheduled_post, post_type = future.result()
                    print(f"{GREEN}{post_type} Scheduled: {scheduled_post} | {human_readable_date} | {image_file} {RESET}")
                except Exception as e:
                    print(f"{RED}Error uploading image ({image_file}): {e}{RESET}")
    
    # Use the updated current_time for album uploads
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
        
        # current_time now starts where the main folder uploads ended
            for root, dirs, files in os.walk(folder_path):
             for dir_name in dirs:
                
                album_folder = os.path.join(root, dir_name)
                # Get the album title from Title.txt file
                album_title = get_album_title(album_folder)
                
                # Convert the current_time to Unix timestamp
                unix_timestamp = int(current_time.timestamp())
                
                # Submit album upload task with the Unix timestamp
                future = executor.submit(upload_albums, album_folder, album_title, str(unix_timestamp))
                futures.append(future)
                
                # Increment current_time by 15 minutes for the next album upload
                current_time += timedelta(minutes=delay_minutes)

        # Wait for all futures to complete
            for future in futures:
                try:
                    human_readable_date, scheduled_post, post_type, album_folder = future.result()
                    print(f"{GREEN}{post_type} Scheduled: {scheduled_post} | {human_readable_date} | {album_folder}{RESET}")
                except Exception as e:
                    print(f"Error uploading Album : ({album_folder})")

    print('Task Completed')







#===============================#



def ipdetails():
    print()
    print(f"{GREEN}Your IP Address Information ")
    print(f"{GREEN}Your public IP address:", ip_info["query"])
    print(f"{GREEN}Location:", f"{ip_info['city']}, {ip_info['regionName']}, {ip_info['country']}")  
    print(f'{RESET}')
def localip():
      try:
        response2 = requests.get('http://ip-api.com/json', proxies=proxies, timeout=10)
        print(f'{GREEN}')
        if response2.status_code == 200:
            global ip_info
            ip_info = response2.json()
        else:
            print(f"Request failed with status code {response2.status_code}")

      except requests.RequestException as e:
        
        print()
        print(f"{RED}Please Check Your Internet Connection")
        input()
        exit()
def get_ip_and_location():
    

    global task_complete
    task_complete = False
    loading_thread = threading.Thread(target=print_loading_rotating_earth)
    loading_thread.start()

    
    
   
    try:
        response2 = requests.get('http://ip-api.com/json', proxies=proxies, timeout=10)        

                
        print(f'{GREEN}')
        if 'country' in response2.text:
            global ip_info
            ip_info = response2.json()
            task_complete = True        
            loading_thread.join()
            sys.stdout.flush()

        
        else:              
               print(f"Request failed with status code {response2.status_code}")
               task_complete = True        
               loading_thread.join()
               sys.stdout.flush()

    except requests.RequestException as e:
        print()
        print(f"{RED}Failed To Connect Proxy | Please Remove Proxy From >>> proxy.txt <<< File or Add New/Valid Proxy")
        print(f"{RED}Make Sure That Your Internet Connection is Stable")
        task_complete = True        
        loading_thread.join()
        sys.stdout.flush()
        input()
        exit()
    print(f'{RESET}')    


def print_loading_rotating_earth():
    symbols = ["-", "\\", "|", "/"]
    i = 0    
    while not task_complete:
        sys.stdout.write(f"\rConnecting You To a Proxy Server {symbols[i % len(symbols)]}")
        sys.stdout.flush()
        time.sleep(0.2)
        i += 1

def check_file_not_in_folder(file_path):
    if not os.path.exists(file_path):
        with open(file_path, 'w') as file:
         pass
    elif not os.path.isfile(file_path):
        with open(file_path, 'w') as file:
         pass
    else:
        return False

def chkipfromserver():
 global proxy 
 file_path = 'proxy.txt'
 if check_file_not_in_folder(file_path):
    pass
 else:
    with open(file_path, 'r') as file:
     first_line = file.readline()
     proxy = first_line.strip()
     if ':' in proxy:
        global proxies
        proxies = {"http": 'http://'+proxy, "https": 'http://'+proxy}
                   
        ask = input('Do You Want To Use Proxy ? Yes/No : ')
        
        if 'y' in ask:
           get_ip_and_location()
        elif 'Y' in ask:
           get_ip_and_location()
        elif 'yes' in ask:
           get_ip_and_location()
        elif 'n' in ask:
           proxies = []
           proxy = []
           localip()
        elif 'N' in ask:
           proxies = []
           proxy = []
           localip()
        elif 'no' in ask:      
           proxies = []
           proxy = []
           localip()
        else:
           print("Please Enter Correct Option : ")
           input("Hit Enter To Go Back")
           chkipfromserver()
           
     else:   
         proxies = []
         proxy = []
         localip()







logo = f'''{CYAN}
 __  __ ___ _____ _   ___ _   _ ___ ___ _  _ ___ ___ ___ ___ _   _ ___ _____ 
|  \/  | __|_   _/_\ | _ ) | | / __|_ _| \| | __/ __/ __/ __| | | |_ _|_   _|
| |\/| | _|  | |/ _ \| _ \ |_| \__ \| || .` | _|\__ \__ \__ \ |_| || |  | |  
|_|  |_|___| |_/_/ \_\___/\___/|___/___|_|\_|___|___/___/___/\___/|___| |_|  
{GREEN}         POST PHOTOS & ALBUMS TO PAGES (From PC) {RESET}
'''
chkipfromserver()


while True:
 print(logo)  
 ipdetails()
 login()
 

 folder_path = input('Input Folder Path : ')
 start_time_input = input("Enter start time (e.g., '12:00AM DD/MM/YYYY'): ")
 delay = int(input('Delay Between Posts in Minutes (e.g., 10'') : '))
 max_workers = int(input('Threads : '))
 group_ids, post_in_group, post_in_page = collect_user_input()
 main(folder_path, start_time_input, delay, max_workers)

